<!doctype html><html lang=en><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><title>My Automated Backups to AWS S3 With Client-Side AES256 | Denis Rechkunov | rdner's blog</title>
<meta name=description content="I'm very paranoid when it comes to my data. For me, the only backup solution that I could possibly use, must be simple and must have client-side AES256 encryption with the passphrase that only I would know."><meta name=author content="Denis Rechkunov"><meta name=copyright content="Denis Rechkunov"><meta property="og:url" content="https://rdner.de/posts/tech/security/s3-aes256-backups/"><meta property="og:site_name" content="rdner's blog"><meta property="og:title" content="My Automated Backups to AWS S3 With Client-Side AES256 | Denis Rechkunov"><meta property="og:description" content="I'm very paranoid when it comes to my data. For me, the only backup solution that I could possibly use, must be simple and must have client-side AES256 encryption with the passphrase that only I would know."><meta property="og:locale" content="en_US"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2019-12-08T00:00:00+00:00"><meta property="article:modified_time" content="2019-12-08T00:00:00+00:00"><meta property="article:tag" content="security"><meta property="article:tag" content="encryption"><meta property="article:tag" content="backup"><meta property="article:tag" content="s3"><meta property="article:tag" content="aws"><meta property="article:tag" content="bash"><meta property="og:image" content="https://rdner.de/posts/tech/security/s3-aes256-backups/cover.jpg"><meta property="og:image:secure_url" content="https://rdner.de/posts/tech/security/s3-aes256-backups/cover.jpg"><meta property="og:image:type" content="image/jpeg"><meta property="og:image" content="https://rdner.de/posts/tech/security/s3-aes256-backups/cover.jpg"><meta property="og:image:secure_url" content="https://rdner.de/posts/tech/security/s3-aes256-backups/cover.jpg"><meta property="og:image:type" content="image/jpeg"><meta name=theme-color content="#5a2673"><meta name=apple-mobile-web-app-capable content="yes"><meta name=apple-mobile-web-app-title content="rdner's blog"><meta name=mobile-web-app-capable content="yes"><meta name=application-name content="rdner's blog"><meta name=msapplication-TileColor content="#5a2673"><meta name=license content="http://creativecommons.org/licenses/by-nc-sa/4.0/"><meta name=theme content="Loud Pragmatic"><link rel=canonical href=https://rdner.de/posts/tech/security/s3-aes256-backups/><style>:root{--main-color:#5a2673;--bg-color:#141116;--highlight-color:#8952A2;--border-color:#D7DADC;--card-bg-color:#252426;--card-overlay-color:rgba(20,17,22,0.6);--text-color:#D7DADC;--secondary-text-color:#C0C0C0;--highlight-text-color:#FFF}</style><link rel=stylesheet href=/css/styles.css type=text/css><link rel=icon href=/favicon.ico sizes=48x48><link rel=icon href=/favicon.svg sizes=any type=image/svg+xml><link rel=apple-touch-icon href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5a2673><link rel=manifest href=/site.webmanifest><link rel=license href=http://creativecommons.org/licenses/by-nc-sa/4.0/><meta name=fediverse:creator content="@rdner@mastodon.social"><script defer data-domain=rdner.de src=https://plausible.io/js/script.js></script></head><body><header class=site-header><nav class="site-nav undecorated"><ul class=no-bullets><li><a href=/><img class=logo alt="website logo" src=/images/logo.svg></a></li><li class=flex-expanded></li><li><a href=/posts/ title="Blog Posts">Posts</a></li><li><a href=/music/ title="Music Releases">Music</a></li><li><a href=/talks/ title="My Talks">Talks</a></li><li><a href=/cv.html title="My Most Recent CV">CV</a></li><li><a href=https://www.linkedin.com/in/rdner title="My LinkedIn Profile" rel="nofollow noreferrer" target=_blank><img src=/images/menu/linkedin.svg alt=LinkedIn></a></li><li><a href=https://github.com/rdner title="My Github Profile" rel="nofollow noreferrer" target=_blank><img src=/images/menu/github.svg alt=Github></a></li><li><a href=https://mastodon.social/@rdner title="My Mastodon Profile" rel="nofollow noreferrer me" target=_blank><img src=/images/menu/mastodon.svg alt=Mastodon></a></li></ul></nav></header><main><div class=container><div class="breadcrumbs undecorated"><span class=breadcrumb><a href=/>Home</a>
</span>→
<span class=breadcrumb><a href=/posts/>Blog Posts</a>
</span>→
<span class=breadcrumb><a href=/posts/tech/>Technology</a>
</span>→
<span class=breadcrumb><a href=/posts/tech/security/>Information Security</a>
</span>→
<span class="final breadcrumb">My Automated Backups to AWS S3 With Client-Side AES256</span></div><article class=post><header class="post-header with-cover" style=background-image:url(/posts/tech/security/s3-aes256-backups/cover.jpg)><h1 class="shadowed unbordered centered">My Automated Backups to AWS S3 With Client-Side AES256</h1><div class=post-summary-card><div class=info><img class=author-picture alt="author picture" src=/images/rdner.jpg><div><div class=author-name>Author:&nbsp;
<a href=mailto:denis@rdner.de>Denis Rechkunov</a></div><div class=facts><time datetime="2019-12-08 00:00:00 +0000 UTC">Dec 8, 2019</time>
&nbsp;/&nbsp;
~1400&nbsp;words
&nbsp;/&nbsp;7&nbsp;min&nbsp;read</div></div></div><p>I'm very paranoid when it comes to my data. For me, the only backup solution that I could possibly use, must be simple and must have client-side AES256 encryption with the passphrase that only I would know.</p><div>Image credit: The bank vault in NoMad Downtown LA. Image by Benoit Linero.</div></div></header><div class=content><aside class="toc undecorated"><nav id=TableOfContents><ul><li><a href=#what-i-was-looking-for-requirements>What I was looking for. Requirements</a></li><li><a href=#3-2-1-backup-rule>3-2-1 Backup Rule</a></li><li><a href=#first-step-encryption>First Step: Encryption</a></li><li><a href=#second-step-storage-in-s3>Second Step: Storage in S3</a><ul><li><a href=#create-a-user>Create a user</a></li><li><a href=#configure-your-aws-cli>Configure your AWS CLI</a></li><li><a href=#create-s3-bucket>Create S3 bucket</a></li><li><a href=#create-a-policy>Create a policy</a></li><li><a href=#use-the-backup-bash-script>Use the backup bash script</a></li></ul></li><li><a href=#fulfilled-requirements>Fulfilled Requirements</a></li></ul></nav></aside><h2 id=what-i-was-looking-for-requirements>What I was looking for. Requirements&nbsp;<a class="undecorated heading-anchor" href=#what-i-was-looking-for-requirements>#</a></h2><p>The reason I didn&rsquo;t just start using some backup software with built-in encryption is a pure lack of trust. So, if you&rsquo;re fine with someone managing your backups, you might think the approach described here is a total overkill. And it&rsquo;s okay. But there are some people out there who have the same trust issues that I do and they might find this article useful, so I write it for them. And also for myself, as a write-up what I did.</p><p>What are my personal requirements to a backup automation:</p><ul><li>The storage back-end must be highly available</li><li>The storage back-end must have versioning</li><li>The client must <strong>not</strong> have permission to destroy or corrupt data</li><li>The client must be transparent and obvious in how it works</li><li>The client must be smart enough to synchronize backups — uploads changes only</li><li>The encryption of my backups must happen on my machine and should prompt for a passphrase during the process. It should be technically impossible for someone except me to access the backups.</li></ul><p>I know, one can argue about the last one because this passphrase is a shared secret created by a human but I can assure you, nobody else knows my passphrase (unless somebody installs a key-logger software on my computer) and the passphrase is really strong (long, special characters, different casing, numbers, etc).</p><h2 id=3-2-1-backup-rule>3-2-1 Backup Rule&nbsp;<a class="undecorated heading-anchor" href=#3-2-1-backup-rule>#</a></h2><p>There is a common rule of backup that says you must be:</p><ul><li>Making at least 3 copies of data, located on physically different storage media;</li><li>Keeping these copies in no less than 2 different formats;</li><li>Always storing at least 1 of these backups off-site (e.g. on the commercial cloud account).</li></ul><p>I don&rsquo;t know where exactly this rule came from but you can definitely find some mentions on the internet (e.g
<a href=https://www.backblaze.com/blog/the-3-2-1-backup-strategy/ rel="nofollow noreferrer" target=_blank>here</a>
and
<a href=https://www.nakivo.com/blog/3-2-1-backup-rule-efficient-data-protection-strategy/ rel="nofollow noreferrer" target=_blank>here</a>
).</p><p>This rule makes sense to me, so I would like to follow this rule as much as I can.</p><p>So, for me it would be:</p><ul><li>3 copies of data: 1 on AWS, 1 on a mSD card, 1 on a USB thumb drive</li><li>2 formats: I guess this is an exception for me, I store only AES256 encrypted TAR files</li><li>1 off-site: 1 backup is on AWS, so technically it&rsquo;s off-site of my laptop. Or I can say that my thumb drive or mSD card is off-site, whatever.</li></ul><p>Before we talk about how I actually store backups, let&rsquo;s talk about the encryption I use.</p><h2 id=first-step-encryption>First Step: Encryption&nbsp;<a class="undecorated heading-anchor" href=#first-step-encryption>#</a></h2><p>Some time ago I wrote a bash script for encrypting a given directory. It&rsquo;s very simple and is based on the GPG symmetric mode and AES256 algorithm. This script creates a TAR archive and then directs it to GPG that prompts for a passphrase and performs the encryption.</p><p>You can find the source code
<a href=https://github.com/rdner/dotfiles/blob/master/files/scripts/vault rel="nofollow noreferrer" target=_blank>here on GitHub</a>
.</p><p>This script produces <code>*.enc</code> files that I can upload or store anywhere without fear that somebody can get access to the content.</p><p>For me, it&rsquo;s the simplest and most reliable solution: GPG is a very reliable tool and I understand 100% what my script is doing because it&rsquo;s so simple.</p><h2 id=second-step-storage-in-s3>Second Step: Storage in S3&nbsp;<a class="undecorated heading-anchor" href=#second-step-storage-in-s3>#</a></h2><p>We&rsquo;re not going to talk about my physical devices, it&rsquo;s pretty much manual work there.
What I want to talk about is how I use AWS CLI to sync the local directory where I store backups with a bucket folder in S3.</p><p>Obviously, you need an AWS account for everything that follows.</p><p>To prepare everything we need:</p><ul><li>Create a user in IAM for running AWS CLI</li><li>Configure your AWS CLI</li><li>Create an S3 bucket and a folder for backups</li><li>Create a policy for the user, so it has write-only access to the bucket folder</li></ul><p>And after the preparation we can just use another bash script.</p><h3 id=create-a-user>Create a user&nbsp;<a class="undecorated heading-anchor" href=#create-a-user>#</a></h3><ul><li>Go to the
<a href=https://console.aws.amazon.com/iam/home#/users rel="nofollow noreferrer" target=_blank>IAM console</a>
and click <code>Add user</code>.</li><li>Type in a desirable user name and check <strong>only</strong> <code>Programmatic access</code>. Click <code>Next: Permissions</code></li><li><strong>Don&rsquo;t</strong> add the user to any groups, just skip the step clicking on <code>Next: Tags</code></li><li>No tags, required, just skip clicking <code>Next: Review</code></li><li>Review the user and submit with <code>Create user</code>. It&rsquo;s okay to have a warning <code>This user has no permissions</code>, we will address it later.</li></ul><h3 id=configure-your-aws-cli>Configure your AWS CLI&nbsp;<a class="undecorated heading-anchor" href=#configure-your-aws-cli>#</a></h3><ul><li>Install AWS CLI, follow
<a href=https://docs.aws.amazon.com/cli/latest/userguide/install-cliv1.html rel="nofollow noreferrer" target=_blank>the official instructions</a>
. e.g. in Debian it&rsquo;s just <code>sudo apt install awscli</code>.</li><li>Go to
<a href=https://console.aws.amazon.com/iam/home#/users rel="nofollow noreferrer" target=_blank>IAM console</a></li><li>Click on your user you created</li><li>Go to <code>Security credentials</code> tab</li><li>Click <code>Create access key</code> and you&rsquo;ll a dialog with <code>Access key ID</code> and <code>Secret access key</code>. <strong>Don&rsquo;t close this dialog</strong>*.</li><li>Go to your terminal and type <code>awscli configure</code></li><li>Follow the
<a href=https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-configure.html rel="nofollow noreferrer" target=_blank>official instructions</a>
, you&rsquo;ll need the <code>Access key ID</code> and <code>Secret access key</code> from the previous step</li></ul><p>Now you should have a ready-to-work AWS CLI setup on your computer.</p><h3 id=create-s3-bucket>Create S3 bucket&nbsp;<a class="undecorated heading-anchor" href=#create-s3-bucket>#</a></h3><ul><li>Go to the
<a href=https://s3.console.aws.amazon.com/s3/home rel="nofollow noreferrer" target=_blank>S3 console</a>
and click <code>Create bucket</code></li><li>Type in a desirable name, select a region and click <code>Next</code></li><li>On the next <code>Configure options</code> step check <code>Keep all versions of an object in the same bucket</code> and click <code>Next</code>.</li><li>On the next <code>Set permissions</code> step make sure it says <code>Block all public access</code> and click <code>Next</code>.</li><li>After reviewing and creating the bucket browse the bucket and create a folder for backups in it</li></ul><h3 id=create-a-policy>Create a policy&nbsp;<a class="undecorated heading-anchor" href=#create-a-policy>#</a></h3><p>Now it&rsquo;s time to allow our CLI user to upload new backups, for this we need to create a policy:</p><ul><li>Go to the
<a href=https://console.aws.amazon.com/iam/home#/users rel="nofollow noreferrer" target=_blank>IAM console</a>
and click on the user you created earlier</li><li>Click <code>Add inline policy</code></li><li>AWS has this visual editor by default but it&rsquo;s easier to put this JSON example here instead of describing where to click:</li></ul><div class=highlight><pre tabindex=0 style=color:#c9c9c9;background-color:#282c34;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-json data-lang=json><span style=display:flex><span><span style=color:#56b6c2>{</span>
</span></span><span style=display:flex><span>    <span style=color:#bc74c4>&#34;Version&#34;</span><span style=color:#56b6c2>:</span> <span style=color:#82cc6a>&#34;2012-10-17&#34;</span><span style=color:#56b6c2>,</span>
</span></span><span style=display:flex><span>    <span style=color:#bc74c4>&#34;Statement&#34;</span><span style=color:#56b6c2>:</span> <span style=color:#56b6c2>[</span>
</span></span><span style=display:flex><span>        <span style=color:#56b6c2>{</span>
</span></span><span style=display:flex><span>            <span style=color:#bc74c4>&#34;Sid&#34;</span><span style=color:#56b6c2>:</span> <span style=color:#82cc6a>&#34;ListBackups&#34;</span><span style=color:#56b6c2>,</span>
</span></span><span style=display:flex><span>            <span style=color:#bc74c4>&#34;Effect&#34;</span><span style=color:#56b6c2>:</span> <span style=color:#82cc6a>&#34;Allow&#34;</span><span style=color:#56b6c2>,</span>
</span></span><span style=display:flex><span>            <span style=color:#bc74c4>&#34;Action&#34;</span><span style=color:#56b6c2>:</span> <span style=color:#82cc6a>&#34;s3:ListBucket&#34;</span><span style=color:#56b6c2>,</span>
</span></span><span style=display:flex><span>            <span style=color:#bc74c4>&#34;Resource&#34;</span><span style=color:#56b6c2>:</span> <span style=color:#82cc6a>&#34;arn:aws:s3:::&lt;bucket-name&gt;&#34;</span>
</span></span><span style=display:flex><span>        <span style=color:#56b6c2>},</span>
</span></span><span style=display:flex><span>        <span style=color:#56b6c2>{</span>
</span></span><span style=display:flex><span>            <span style=color:#bc74c4>&#34;Sid&#34;</span><span style=color:#56b6c2>:</span> <span style=color:#82cc6a>&#34;UploadBackups&#34;</span><span style=color:#56b6c2>,</span>
</span></span><span style=display:flex><span>            <span style=color:#bc74c4>&#34;Effect&#34;</span><span style=color:#56b6c2>:</span> <span style=color:#82cc6a>&#34;Allow&#34;</span><span style=color:#56b6c2>,</span>
</span></span><span style=display:flex><span>            <span style=color:#bc74c4>&#34;Action&#34;</span><span style=color:#56b6c2>:</span> <span style=color:#82cc6a>&#34;s3:PutObject&#34;</span><span style=color:#56b6c2>,</span>
</span></span><span style=display:flex><span>            <span style=color:#bc74c4>&#34;Resource&#34;</span><span style=color:#56b6c2>:</span> <span style=color:#82cc6a>&#34;arn:aws:s3:::&lt;bucket-name&gt;/&lt;backup-folder&gt;/*&#34;</span>
</span></span><span style=display:flex><span>        <span style=color:#56b6c2>}</span>
</span></span><span style=display:flex><span>    <span style=color:#56b6c2>]</span>
</span></span><span style=display:flex><span><span style=color:#56b6c2>}</span>
</span></span></code></pre></div><p>Replace <code>&lt;bucket-name></code> and <code>&lt;backup-folder></code> with your values. <code>s3:ListBucket</code> permission is required for the <code>aws s3 sync</code> command that we&rsquo;re going to use, so it&rsquo;s able to compare file sizes and modification dates.</p><h3 id=use-the-backup-bash-script>Use the backup bash script&nbsp;<a class="undecorated heading-anchor" href=#use-the-backup-bash-script>#</a></h3><p>I wrote a simple bash script that finds all files with <code>.enc</code> extension in the current directory and its sub-directories and uploads them to the given location on S3.</p><p>You can view and copy the script from my
<a href=https://github.com/rdner/dotfiles/blob/master/files/scripts/backup rel="nofollow noreferrer" target=_blank>repository on GitHub</a>
.</p><p>Now, when our S3 bucket exists and we have an IAM user for our CLI that has a policy to write to a backup folder on the bucket, we can finally run the script:</p><div class=highlight><pre tabindex=0 style=color:#c9c9c9;background-color:#282c34;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-bash data-lang=bash><span style=display:flex><span>backup s3://&lt;bucket-name&gt;/&lt;backup-folder&gt;
</span></span></code></pre></div><p>This script is using <code>aws s3 sync</code> command that checks if the local file matches a remote file by size and modification date and if they match, it does not upload your local file anywhere.</p><h2 id=fulfilled-requirements>Fulfilled Requirements&nbsp;<a class="undecorated heading-anchor" href=#fulfilled-requirements>#</a></h2><p>As you might remember, I had my very strict requirements in the beginning, how does this approach fulfill them? Let&rsquo;s have a look:</p><ul><li>The storage back-end must be highly available — it&rsquo;s S3</li><li>The storage back-end must have versioning — we turned it on when created the bucket</li><li>The client must <strong>not</strong> have permission to destroy or corrupt data — our policy makes sure the script is allowed to only put objects, can&rsquo;t read or delete them. The user is allowed to upload a file with the same name but it won&rsquo;t corrupt data just will create a new version of it</li><li>The client must be transparent and obvious in how it works — just small bash scripts that you can read and understand</li><li>The client must be smart enough to synchronize backups — <code>aws s3 sync</code> uploads only changed or new files to the bucket</li><li>The encryption of my backups must happen on my machine — the first short script also fulfills this requirement for me.</li></ul><p>I admit, this setup is not for everyone and it&rsquo;s far from being simple but if you&rsquo;re working with AWS already it might suit you.</p><p>I hope you learned something from this article. Take care.</p><p>P.S. Please plan your expenses using S3 on AWS in advance. I&rsquo;m not responsible for any unexpected costs.</p></div></article><aside class=separated aria-label="Recent Posts"><h2>Other Posts</h2><ul class="no-bullets undecorated previews"><li class="posts-section preview with-cover shadowed" style=background-image:url(/posts/sport/im-70.3/cover.jpg)><a class=unpadded href=/posts/sport/im-70.3/><article><header><h3 class=title>My Road to IRONMAN 70.3</h3></header><div class=flex-expanded></div><div class=details><p class=content>This is a story of a big life change. One commercial inspired my to take on one of the hardest challenges of my life.</p><div class=facts><time datetime="2023-10-01 00:00:00 +0000 UTC">Oct 1, 2023</time>
&nbsp;/&nbsp;
~4400&nbsp;words
&nbsp;/&nbsp;21&nbsp;min&nbsp;read</div></div></article></a></li><li class="posts-section preview with-cover shadowed" style=background-image:url(/posts/sport/why-run/cover.jpg)><a class=unpadded href=/posts/sport/why-run/><article><header><h3 class=title>Why Run?</h3></header><div class=flex-expanded></div><div class=details><p class=content>Recently quite a few people asked me "Why are you running?", sometimes even followed by something like "it's stupid" or whatever to hint me that I should not. I hope to be able to just send a link to this article next time.</p><div class=facts><time datetime="2022-11-11 00:00:00 +0000 UTC">Nov 11, 2022</time>
&nbsp;/&nbsp;
~2100&nbsp;words
&nbsp;/&nbsp;10&nbsp;min&nbsp;read</div></div></article></a></li><li class="posts-section preview with-cover shadowed" style=background-image:url(/posts/tech/security/privacy-tips/cover.jpg)><a class=unpadded href=/posts/tech/security/privacy-tips/><article><header><h3 class=title>Paranoid Habits. Privacy Tips</h3></header><div class=flex-expanded></div><div class=details><p class=content>This is another write up of my recent talk where I share some information about the modern era of data collection and how you can keep your privacy. At least partially.</p><div class=facts><time datetime="2021-03-10 12:01:16 +0100 +0100">Mar 10, 2021</time>
&nbsp;/&nbsp;
~4000&nbsp;words
&nbsp;/&nbsp;19&nbsp;min&nbsp;read</div></div></article></a></li><li class="posts-section preview with-cover shadowed" style=background-image:url(/posts/motorcycle/granada-spain/cover.jpg)><a class=unpadded href=/posts/motorcycle/granada-spain/><article><header><h3 class=title>Riding in Granada, Spain</h3></header><div class=flex-expanded></div><div class=details><p class=content>This year comes to its end and it's time to summarize. The best thing that happened to me this year was the motorbike trip in Spain, I'd like to share what was so amazing about it. Videos included.</p><div class=facts><time datetime="2019-12-29 00:00:00 +0100 +0100">Dec 29, 2019</time>
&nbsp;/&nbsp;
~1100&nbsp;words
&nbsp;/&nbsp;5&nbsp;min&nbsp;read</div></div></article></a></li></ul></aside></div></main><footer class=site-footer><a href=https://rdner.de/>rdner's blog</a>&nbsp;&copy;&nbsp;2015-2025&nbsp;by&nbsp;Denis Rechkunov&nbsp;<a href=mailto:denis@rdner.de>(denis@rdner.de)</a>.<br>All content is licensed under <a href=https://creativecommons.org/licenses/by-nc-sa/4.0/>CC BY-NC-SA 4.0</a><img src=https://mirrors.creativecommons.org/presskit/icons/cc.svg style=max-width:1em;max-height:1em;margin-left:.2em alt="Creative Commons"><img src=https://mirrors.creativecommons.org/presskit/icons/by.svg style=max-width:1em;max-height:1em;margin-left:.2em alt=Attribution><img src=https://mirrors.creativecommons.org/presskit/icons/nc.svg style=max-width:1em;max-height:1em;margin-left:.2em alt=Non-commercial><img src=https://mirrors.creativecommons.org/presskit/icons/sa.svg style=max-width:1em;max-height:1em;margin-left:.2em alt=Share-alike>.<script type=text/javascript>w=document.getElementById("whoami"),w&&(w.onclick=()=>eval(atob("ZG9jdW1lbnQubG9jYXRpb24gPSAiL3ZpZGVvcy8xLm1wNCI=")))</script></footer></body></html>